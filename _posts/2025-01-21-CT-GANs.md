## Conditional-Table-GAN

---

![alt text](https://github.com/StefanoPenazzi2/StefanoPenazzi2.github.io/blob/main/imgs/ctgans/ctgans_architecture.png?raw=true)

**Synthetic Tabula Data Generation** 

<style scoped>
table {
  font-size: 11px;
}
</style>

| Method                     | Pros                                                                                   | Cons                                                                                       |
|----------------------------|----------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------|
| Decision Trees             | - Easy to interpret and implement. <br> - Handles both categorical and continuous data. | - Prone to overfitting. <br> - Limited in modeling interactions between variables.          |
| Bayesian Networks          | - Efficiently models conditional dependencies. <br> - Provides insights into causal relationships. | - Computationally intensive for large datasets. <br> - Requires domain expertise.         |
| Spatial Decomposition Trees | - Well-suited for spatial data. <br> - Captures spatial dependencies effectively.      | - Complexity increases with dimensionality. <br> - Requires domain-specific tuning.        |
| Copulas                    | - Models non-linear dependencies. <br> - Separate modeling of margins and dependencies. | - Difficult to specify copula types. <br> - Computationally demanding for high-dimensional data. |
| Markov Chain Monte Carlo (MCMC) | - Flexible and applicable to various distributions. <br> - Strong theoretical foundation.   | - Computationally expensive. <br> - Requires careful tuning.                               |
| Bootstrapping              | - Simple and non-parametric. <br> - Useful for small samples.                          | - May not capture data complexity. <br> - Produces highly similar samples.                |

**Mode-specific Normalization**

**Conditional Vector**

**Generator Loss**

**Training-by-sampling**



$$ 
\min_{\theta} \max_{\omega} F(\theta, \omega) = \min_{\theta} \max_{\omega} \left( \mathbb{E}_{x \sim P} \left[g_f(V_\omega(x | m_i^k))\right] + \mathbb{E}_{x \sim Q_\theta} \left[\log(-g_f(V_\omega(x | m_i^k)))\right] + 1 + \lambda \cdot H(m_i^k, \hat{m_i^k}) \right) 
$$


[//]: # ($$ )
[//]: # (F&#40;\theta, \omega&#41; = \mathbb{E}_{x \sim P} \left[g_f&#40;V_\omega&#40;x | m_i^k&#41;&#41;\right] + \mathbb{E}_{x \sim Q_\theta} \left[\log&#40;-g_f&#40;V_\omega&#40;x | m_i^k&#41;&#41;&#41;\right] + 1 + \lambda \cdot H&#40;m_i^k, \hat{m_i^k}&#41; )
[//]: # ($$)
