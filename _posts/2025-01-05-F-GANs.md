## f-GAN

---

![alt text](https://github.com/StefanoPenazzi2/StefanoPenazzi2.github.io/blob/main/imgs/fgans/fgans_architecture.png?raw=true)


| Name                | Output activation $g_f$                   | dom $f^*$        | Conjugate $f^*(t)$            | $f'(1)$    |
|---------------------|---------------------------------------------|--------------------|---------------------------------|-------------|
| Kullback-Leibler (KL) | $v$                                       | $\mathbb{R}$     | $\exp(t - 1)$                | 1           |
| Reverse KL          | $- \exp(-v)$                              | $\mathbb{R}_-$   | $-1 - \log(-t)$              | -1          |
| Pearson $\chi^2$  | $v$                                       | $\mathbb{R}$     | $\frac{1}{4}t^2 + t$         | 0           |
| Squared Hellinger   | $1 - \exp(-v)$                            | $t < 1$          | $\frac{t}{1-t}$              | 0           |
| Jensen-Shannon      | $\log(2) - \log(1 + \exp(-v))$            | $t < \log(2)$    | $- \log(2 - \exp(t))$        | 0           |
| GAN                 | $- \log(1 + \exp(-v))$                    | $\mathbb{R}_-$   | $- \log(1 - \exp(t))$        | $- \log(2)$ |


$$

\min_{\nu} \sup_{T} \left( \mathbb{E}_{x \sim P}[T(x)] - \mathbb{E}_{x \sim Q_\theta}[f^*(T(x))] \right).

$$

The associated min-max problem is typically structured as the generator and discriminator trying to optimize opposing objectives

$$
\min_{\theta} \max_{\omega} F(\theta, \omega) = \mathbb{E}_{x \sim P} \left[g_f(V_\omega(x))\right] + \mathbb{E}_{x \sim Q_\theta} \left[-f^*(g_f(V_\omega(x)))\right].
$$

- $\min_{\theta}$: The generator minimizes the function to improve its output.
- $\max_{\omega}$: The discriminator maximizes the function to distinguish between real and generated samples effectively. 