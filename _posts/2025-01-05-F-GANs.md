## f-GAN

---

![alt text](https://github.com/StefanoPenazzi2/StefanoPenazzi2.github.io/blob/main/imgs/fgans/fgans_architecture.png?raw=true)

<style scoped>
table {
  font-size: 11px;
}
</style>

| Name                    | $D_f(P \| Q)$                                                                                                                                  | Generator $f(u)$                                          |
|-------------------------|------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------|
| Total Variation         | $\frac{1}{2} \int \mid p(x) - q(x) \mid \, dx$                                                                                                 | $\frac{1}{2} \mid u - 1 \mid$                                 |
| Kullback-Leibler        | $\int p(x) \log \frac{p(x)}{q(x)} \, dx$                                                                                                       | $u \log u$                                                |
| Reverse Kullback-Leibler | $\int q(x) \log \frac{q(x)}{p(x)} \, dx$                                                                                                       | $-\log u$                                                 |
| Pearson $\chi^2$      | $\int \frac{(q(x) - p(x))^2}{p(x)} \, dx$                                                                                                      | $(u - 1)^2$                                               |
| Neyman $\chi^2$       | $\int \frac{(p(x) - q(x))^2}{q(x)} \, dx$                                                                                                      | $\frac{(1 - u)^2}{u}$                                     |
| Squared Hellinger       | $\int \left( \sqrt{p(x)} - \sqrt{q(x)} \right)^2 \, dx$                                                                                        | $(\sqrt{u} - 1)^2$                                        |
| Jeffrey                 | $\int (p(x) - q(x)) \log \frac{p(x)}{q(x)} \, dx$                                                                                              | $(u - 1) \log u$                                          |
| Jensen-Shannon          | $\frac{1}{2} \int p(x) \log \frac{2p(x)}{p(x) + q(x)} + q(x) \log \frac{2q(x)}{p(x) + q(x)} \, dx$                                             | $- (u+1) \log \frac{1+u}{2} + u \log u$                   |
| Jensen-Shannon-weighted | $\int \pi p(x) \log \frac{\pi p(x)}{\pi p(x) + (1-\pi) q(x)} + (1-\pi) q(x) \log \frac{(1-\pi) q(x)}{\pi p(x) + (1-\pi) q(x)} \, dx - \log(4)$ | $u \log u - (1 - \pi + \pi u) \log(1 - \pi + \pi u)$      |
| GAN                     | $- \int p(x) \log q(x) + (1 - p(x)) \log(1 - q(x)) \, dx$                                                                                      | $u \log u - (u + 1) \log (u + 1)$                         |
| $\alpha$-divergence   | $\frac{1}{\alpha(\alpha - 1)} \int (p(x)^\alpha q(x)^{1-\alpha} - 1 - \alpha (q(x) - p(x))) \, dx$                                             | $\frac{u^\alpha - 1 - \alpha(u - 1)}{\alpha(\alpha - 1)}$ |


The associated min-max problem is typically structured as the generator and discriminator trying to optimize opposing objectives

$$
\min_{\theta} \max_{\omega} F(\theta, \omega) = \mathbb{E}_{x \sim P} \left[g_f(V_\omega(x))\right] + \mathbb{E}_{x \sim Q_\theta} \left[-f^*(g_f(V_\omega(x)))\right].
$$

- $\min_{\theta}$: The generator minimizes the function to improve its output.
- $\max_{\omega}$: The discriminator maximizes the function to distinguish between real and generated samples effectively. 

**algorithm**

At iteration $t-1$, we begin by finding a suboptimal discriminator $g_f(V_{\omega(t-1)}(x))$ for the current
density output from the generator $Q_{\theta(t-2)}$ which is assumed fixed in this iteration.
We then update the density $Q_{\theta(t-2)} \rightarrow Q_{\theta(t)}$ fixing the updated discriminator
$g_f(V_{\omega(t-1)}(x))$ to enhance accuracy. Repeating this cycle ultimately guides us to the desired solution.

Since $P$ and $Q$ are unknown through the process but we can sample from them the expected value is estimated as follow:

$$

\mathbb{E}_{x \sim P} \left[g_f(V_\omega(x))\right] \approx \frac{1}{|A|} \sum_{x \in A} g_f(V_\omega(x)),

$$

$$

 \mathbb{E}_{x \sim Q_\theta} \left[-f^*(g_f(V_\omega(x)))\right] \approx \frac{1}{|B|} \sum_{z \in B} -f^*(g_f(V_\omega(x)))

$$